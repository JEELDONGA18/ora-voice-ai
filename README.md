# ğŸ™ï¸ Ora â€” Voice-First Conversational AI

Ora is a **next-generation voice-driven AI experience** designed to feel **natural, interruptible, and human**.  
Built for the **ElevenLabs Ã— Google Cloud AI Challenge**, Ora enables users to interact **entirely through speech**, combining real-time microphone input, intelligent reasoning, and expressive AI voice responses.

---

## ğŸŒ Live Demo & Video

- ğŸ”— **Live Demo:** (add link here)
- ğŸ“¹ **Full Working Demo (1â€“2 min):** (add YouTube / Loom link here)

---

## âœ¨ Key Features

- ğŸ¤ Push-to-Talk Voice Interaction (Mouse + Spacebar)
- ğŸ§  Context-Aware Conversational AI
- ğŸ”Š Human-Like AI Voice (ElevenLabs)
- ğŸ“Š Real-Time Waveform Visualization
- ğŸ” Interruptible Conversations
- ğŸ¨ Dark Minimal UI with Soft Green Accents
- âš¡ Low-Latency, Session-Based Interaction

---

## ğŸ§­ Pages Overview

### 1ï¸âƒ£ Landing Page
A visually rich introduction to Ora.

**Includes:**
- Animated hero section
- Feature cards with advanced animations
- Carousel showcasing working UI videos
- Voice experience preview
- Call-to-action section
- Footer with contact & credits

---

### 2ï¸âƒ£ Voice App (Working Page)
The core experience of Ora.

**Capabilities:**
- Microphone permission handling
- Push-to-talk interaction
- Dynamic waveform animations per state
- Live conversation bubbles (User â†” AI)
- Streaming AI responses
- AI voice playback
- Error handling & recovery
- Session-aware conversation flow

---

### 3ï¸âƒ£ About Page
A polished presentation of:
- Team members & roles
- Oraâ€™s internal workflow
- Technology acknowledgements

---

## ğŸ”„ Workflow of Ora (System Flow)

Ora follows a structured, real-time voice interaction workflow that begins with microphone permission validation, followed by continuous audio capture from the userâ€™s device. The captured audio stream is analyzed in real time to detect speech activity and silence, after which valid speech segments are forwarded to the AI reasoning layer powered by Google Cloud Vertex AI / Gemini. The AI processes user intent within an active conversational session, preserving contextual continuity across interactions. Once a response is generated, it is passed to the voice synthesis layer using ElevenLabs, where speech is produced and streamed back to the client for immediate playback. Throughout this pipeline, Ora maintains explicit system statesâ€”Idle, Listening, Processing, Responding, and Error Handlingâ€”to ensure robust recovery from permission denials, network failures, or audio playback issues, enabling a seamless, low-latency, and fully voice-driven conversational experience.

---

## ğŸ›ï¸ System States

| State | Description |
|------|------------|
| Idle | Waiting for user input |
| Listening | Capturing microphone input |
| Processing | AI reasoning in progress |
| Speaking | AI voice playback |
| Error | Permission, network, or audio failure |

Each state is visually represented using **dynamic waveform animations**.

---

## ğŸ§‘â€ğŸ’» Team

| Name | Role |
|-----|------|
| **Jeel Donga** | UI / UX Engineer â€” Designed the complete visual system, animations, and voice-first UX |
| **Yash Dilkhush** | Backend & Cloud Engineer â€” APIs, sessions, and scalable architecture |
| **Dhyey Desai** | AI & Prompt Engineer â€” Conversational intelligence and prompt design |
| **Dhrumil Khatiwala** | Voice & Audio Engineer â€” Microphone capture, waveform visualization, audio streaming |

---

## ğŸ§  Tech Stack

### Frontend
- React.js
- Tailwind CSS
- Framer Motion
- React Router

### AI & Voice
- **ElevenLabs** â€” AI Voice Synthesis
- **Google Cloud Vertex AI / Gemini** â€” Conversational Intelligence

### Browser APIs
- Web Audio API
- MediaDevices API

---

## ğŸ“‚ Project Structure (Simplified)
frontend/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ voice/
â”‚ â”‚ â”œâ”€â”€ layout/
â”‚ â”‚ â””â”€â”€ sections/
â”‚ â”œâ”€â”€ pages/
â”‚ â”œâ”€â”€ hooks/
â”‚ â”œâ”€â”€ services/
â”‚ â””â”€â”€ styles/
â”‚
â””â”€â”€ README.md

---

## ğŸ™ Credits & Acknowledgements

We sincerely thank:

- **Google Cloud Vertex AI / Gemini** â€” for powering intelligent, context-aware conversations
- **ElevenLabs** â€” for providing expressive, human-like AI voice synthesis

Their platforms made Oraâ€™s natural voice experience possible.

---

## ğŸš€ Future Enhancements

- Live speech-to-text transcription
- True streaming audio from ElevenLabs
- Multi-language support
- Mobile-optimized voice UX
- Persistent session memory

---

## ğŸ“¬ Contact & Collaboration

ğŸ“§ **Email:** jeeldonga18@gmail.com  
ğŸ“§ **CC:** dhyeydesai2626@gmail.com, yashdilkhush96@gmail.com  
ğŸ’¬ **Subject:** Collaboration with Ora or Query about Ora

---

## â­ Final Note

Ora is not just a demo â€” it is a **foundation for voice-first humanâ€“AI interaction**, designed with performance, UX, and realism in mind.